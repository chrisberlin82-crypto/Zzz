# ============================================================
# MED Rezeption LIVE - Umgebungsvariablen
# ============================================================
# Kopiere diese Datei zu .env und passe die Werte an:
#   cp .env.beispiel .env
#   nano .env
# ============================================================

# --- Flask Frontend (LLM fuer Chat-Assistent) ---
# Provider: "anthropic" (Claude) oder "openai" (GPT)
MED_LLM_PROVIDER=anthropic

# API-Key fuer den gewaehlten Provider
# Anthropic: https://console.anthropic.com/settings/keys
# OpenAI: https://platform.openai.com/api-keys
MED_LLM_API_KEY=sk-ant-DEIN-API-KEY-HIER

# Optional: Modell ueberschreiben (leer = Standard)
MED_LLM_MODEL=

# --- Branche (Standard fuer neue Installationen) ---
# arztpraxis | zahnarzt | anwalt | steuerberater | friseur | werkstatt | tierarzt | allgemein
MED_BRANCHE=arztpraxis

# --- Flask ---
FLASK_ENV=production

# --- Voicebot Engine (FastAPI) ---
# LLM wird automatisch auf http://ollama:11434 gesetzt (Docker-intern)
MR_LLM_MODEL=llama3.1:8b-instruct-q4_K_M
MR_STT_MODEL=small
MR_STT_DEVICE=cpu
MR_STT_COMPUTE_TYPE=int8
MR_TTS_MODEL=de_DE-thorsten-high
MR_TTS_SPEED=1.0
MR_AUDIO_HINTERGRUND_TYP=buero
MR_AUDIO_HINTERGRUND_AKTIV=true
MR_AUDIO_HINTERGRUND_LAUTSTAERKE=0.08
MR_DEBUG=false
MR_SECRET_KEY=CHANGE-ME-IN-PRODUCTION
